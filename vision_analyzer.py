# --------------------------------------------------
# vision_router.py (Hybrid RAG + Upcycling Tips ë²„ì „)
# --------------------------------------------------
import base64
import json
import math
import os
import re
from io import BytesIO
from pathlib import Path

from dotenv import load_dotenv
from fastapi import APIRouter, File, Form, HTTPException, UploadFile
from fastapi.responses import JSONResponse
from openai import OpenAI
from PIL import Image

# âœ… embedding_util ì„í¬íŠ¸
from embedding_util import get_text_embeddings

# --------------------------------------------------
# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.envë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ìë™ íƒìƒ‰)
# --------------------------------------------------
ROOT_DIR = Path(__file__).resolve().parent  # cleanbin í´ë” ê¸°ì¤€
ENV_PATH = ROOT_DIR / ".env"

load_dotenv(dotenv_path=ENV_PATH)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY2")
if not OPENAI_API_KEY:
    raise RuntimeError(f"í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEY2ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (.env: {ENV_PATH})")

client = OpenAI(api_key=OPENAI_API_KEY)

# ëª¨ë¸ê³¼ ì„¤ì •
DEFAULT_MODEL = "gpt-4.1-mini"
MAX_SIDE = 1280
EMBED_PATH = ROOT_DIR / "data" / "embedding.json"  # âœ… RAG ë°ì´í„° ê²½ë¡œ

PROMPT_VISION = (
    """
    ë‹¤ìŒ ì¬í™œìš©í’ˆ ì‚¬ì§„ì´ ë¬´ìŠ¨ ë¬¼ê±´ì¸ì§€ jsonìœ¼ë¡œ ëª…ì‚¬ë¡œ ë°˜í™˜í•´ì¤˜.
    ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•´:
    {"items": ["í”Œë¼ìŠ¤í‹±ë³‘", "ì¢…ì´ìƒì", "ìœ ë¦¬ë³‘", "ì¢…ì´ì»µ"],
    "materials": ["ë¹„ë‹ë¥˜", "í”Œë¼ìŠ¤í‹±", "ì¢…ì´", "ìœ ë¦¬", "ê¸ˆì†", "ê³ ì² ","ìŠ¤í‹°ë¡œí¼"],
    "details": ["ëšœê»‘ì´ ìˆëŠ” í”Œë¼ìŠ¤í‹±ë³‘", "ë°•ìŠ¤ í˜•íƒœì˜ ì¢…ì´ìƒì", "íˆ¬ëª…í•œ ìœ ë¦¬ë³‘", "ì§€ì €ë¶„í•œ ì¢…ì´ì»µ"]}
    ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.
    """
)

PROMPT_RAG_GUIDE = (
    """
    ë‹¹ì‹ ì€ í•œêµ­ì˜ ì¬í™œìš© ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ìœ ì‚¬ í’ˆëª©ì˜ ì¬í™œìš© ê°€ì´ë“œì…ë‹ˆë‹¤.
    ì´ ë‚´ìš©ì„ ì°¸ê³ í•˜ë˜ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ½ê³  ì¼ê´€ì„± ìˆê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

    ê° í’ˆëª©ë³„ë¡œ ë‹¨ê³„ë³„ ì ˆì°¨ë¥¼ í•œêµ­ì–´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.
    ì˜ˆì‹œ:
    [
      "#1. í”Œë¼ìŠ¤í‹±ë³‘ì€ ë‚´ìš©ë¬¼ì„ ë¹„ìš°ì„¸ìš”.",
      "#2. ë¼ë²¨ê³¼ ëšœê»‘ì„ ì œê±°í•˜ì„¸ìš”.",
      "#3. í”Œë¼ìŠ¤í‹± ì „ìš© ìˆ˜ê±°í•¨ì— ë„£ìœ¼ì„¸ìš”."
    ]

    ë°˜ë“œì‹œ JSON í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
    """
)

PROMPT_UPCYCLING_TIP = (
    """
    ë‹¹ì‹ ì€ í™˜ê²½ ì¹œí™”ì ì¸ ì—…ì‚¬ì´í´ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ ì¬í™œìš©í’ˆ ëª©ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ê° í’ˆëª©ì„ ì°½ì˜ì ìœ¼ë¡œ ì¬í™œìš©í•˜ê±°ë‚˜ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì•„ì´ë””ì–´ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.
    ê° í’ˆëª©ë‹¹ í•˜ë‚˜ì”©, ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
    ì˜ˆì‹œ:
    ["í”Œë¼ìŠ¤í‹±ë³‘ì€ ë¬¼ë¿Œë¦¬ê°œë‚˜ í™”ë¶„ìœ¼ë¡œ ì¬í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
     "ìœ ë¦¬ë³‘ì€ ì¡°ëª… ì¥ì‹ì´ë‚˜ ê½ƒë³‘ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."]

    ë°˜ë“œì‹œ JSON í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
    """
)

router = APIRouter(prefix="/vision", tags=["GPT Vision Analyzer"])


# --------------------------------------------------
# ğŸ”¹ ìœ í‹¸ í•¨ìˆ˜ë“¤
# --------------------------------------------------
def image_bytes_to_data_url(b: bytes, ctype: str = "image/png") -> str:
    b64 = base64.b64encode(b).decode("utf-8")
    return f"data:{ctype};base64,{b64}"


def cosine_similarity(v1, v2):
    """ë‘ ë²¡í„° ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°."""
    dot = sum(a * b for a, b in zip(v1, v2))
    norm1 = math.sqrt(sum(a * a for a in v1))
    norm2 = math.sqrt(sum(b * b for b in v2))
    return dot / (norm1 * norm2 + 1e-9)


def load_embedding_data(path: Path):
    """embedding.json ë¡œë“œ."""
    if not path.exists():
        raise FileNotFoundError(f"ì„ë² ë”© íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data.get("embeddings", [])


def call_gpt_vision(data_url: str, model: str = DEFAULT_MODEL) -> str:
    response = client.responses.create(
        model=model,
        input=[
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": PROMPT_VISION},
                    {"type": "input_image", "image_url": data_url},
                ],
            }
        ],
    )
    return response.output_text.strip()


# --------------------------------------------------
# ğŸ”¹ Vision + Hybrid RAG + Upcycling Tips ì—”ë“œí¬ì¸íŠ¸
# --------------------------------------------------
@router.post("/analyze")
def analyze_image(file: UploadFile = File(...), model: str = Form(DEFAULT_MODEL)):
    """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  GPTê°€ RAG ì •ë³´ë¥¼ ì°¸ê³ í•´ ì¬í™œìš© ì ˆì°¨ì™€ ì—…ì‚¬ì´í´ë§ íŒì„ ìƒì„±."""
    try:
        # -----------------------------
        # 1ï¸âƒ£ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        # -----------------------------
        content = file.file.read()
        img = Image.open(BytesIO(content)).convert("RGB")

        w, h = img.size
        scale = max(w, h) / float(MAX_SIDE)
        if scale > 1.0:
            img = img.resize((int(w / scale), int(h / scale)), Image.LANCZOS)

        fmt = "PNG" if file.filename.lower().endswith(".png") else "JPEG"
        ctype = "image/png" if fmt == "PNG" else "image/jpeg"
        bio = BytesIO()
        img.save(bio, format=fmt, quality=90 if fmt == "JPEG" else None)
        data_url = image_bytes_to_data_url(bio.getvalue(), ctype=ctype)

        # -----------------------------
        # 2ï¸âƒ£ Visionìœ¼ë¡œ í’ˆëª© ì¶”ì¶œ
        # -----------------------------
        result_text = call_gpt_vision(data_url, model=model)
        match = re.search(r"\{[\s\S]*\}", result_text)
        if not match:
            raise ValueError("No JSON object found in GPT response")

        parsed = json.loads(match.group(0))
        items = parsed.get("items", [])
        if not items:
            return JSONResponse(
                {
                    "result": {
                        "message": "ì˜ëª»ëœ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.",
                        "items": [],
                        "disposal_methods": ["ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."],
                        "tips": [],
                    }
                },
                status_code=200,
            )

        # -----------------------------
        # 3ï¸âƒ£ RAGì—ì„œ ìœ ì‚¬ í’ˆëª© ì •ë³´ ê²€ìƒ‰
        # -----------------------------
        db_embeddings = load_embedding_data(EMBED_PATH)
        item_vecs = get_text_embeddings(items)

        rag_contexts = []
        for item, vec in zip(items, item_vecs):
            best_sim = -1
            best_info = None
            for entry in db_embeddings:
                sim = cosine_similarity(vec, entry["embedding"])
                if sim > best_sim:
                    best_sim = sim
                    best_info = entry
            if best_info:
                rag_contexts.append(
                    f"- ìœ ì‚¬ í’ˆëª©: {best_info['item_name']} ({best_sim:.3f})\n"
                    f"- ë¶„ë¥˜: {best_info['disposal_category']}\n"
                    f"- ì²˜ë¦¬ ê°€ì´ë“œ: {best_info['disposal_method']}"
                )

        rag_context_text = "\n\n".join(rag_contexts)

        # -----------------------------
        # 4ï¸âƒ£ GPTì—ê²Œ ìµœì¢… disposal_methods ìƒì„± ìš”ì²­
        # -----------------------------
        gpt_prompt = (
            PROMPT_RAG_GUIDE
            + "\n\n[í˜„ì¬ ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í’ˆëª©]\n"
            + json.dumps(items, ensure_ascii=False)
            + "\n\n[ì°¸ê³ í•  ì¬í™œìš© ë°ì´í„°]\n"
            + rag_context_text
        )

        response = client.responses.create(
            model=model,
            input=[
                {"role": "user", "content": [{"type": "input_text", "text": gpt_prompt}]}
            ],
        )

        disposal_text = response.output_text.strip()

        try:
            disposal_methods = json.loads(disposal_text)
        except json.JSONDecodeError:
            disposal_methods = [
                s.strip() for s in re.split(r"[\n\-â€¢]", disposal_text) if s.strip()
            ]

        # -----------------------------
        # 5ï¸âƒ£ GPTì—ê²Œ ì—…ì‚¬ì´í´ë§ íŒ ìƒì„± ìš”ì²­
        # -----------------------------
        tip_prompt = (
            PROMPT_UPCYCLING_TIP
            + "\n\n[í’ˆëª© ë¦¬ìŠ¤íŠ¸]\n"
            + json.dumps(items, ensure_ascii=False)
        )

        tip_response = client.responses.create(
            model=model,
            input=[
                {"role": "user", "content": [{"type": "input_text", "text": tip_prompt}]}
            ],
        )

        tip_text = tip_response.output_text.strip()

        try:
            tips = json.loads(tip_text)
        except json.JSONDecodeError:
            tips = [s.strip() for s in re.split(r"[\n\-â€¢]", tip_text) if s.strip()]

        
        # -----------------------------
        # 6ï¸âƒ£ í’ˆëª©ë³„ ëŒ€í‘œ ì´ë¯¸ì§€ URL ì¶”ê°€
        # -----------------------------
        IMAGE_DIR = ROOT_DIR / "image"
        IMAGE_MAP = {
            "í”Œë¼ìŠ¤í‹±": "Pet.png",
            "í˜íŠ¸": "Pet.png",
            "ë³‘": "Pet.png",
            "ìº”": "Can.png",
            "ì¢…ì´": "Paper.png",
            "ìƒì": "Paper.png",
            "ë°•ìŠ¤": "Paper.png",
            "ìœ ë¦¬": "Glass.png",
            #"ìŠ¤í‹°ë¡œí¼": "Styrofoam.png",
            #"ë¹„ë‹": "Vinyl.png",
            #"ê³ ì² ": "Metal.png",
            #"ì² ": "Metal.png",
        }

        selected_img = None
        for item in items:
            normalized = re.sub(r"\s+", "", item)  # ê³µë°± ì œê±°
            for key, fname in IMAGE_MAP.items():
                if key in normalized:
                    selected_img = fname
                    break
            if selected_img:
                break

        if selected_img:
            # í”„ë¡ íŠ¸ì—”ë“œ ë Œë”ë§ìš© URL (FastAPI static mount ê¸°ì¤€)
            image_url = f"/static/{selected_img}"
        else:
            image_url = None  # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ None

        parsed["image_url"] = image_url

        # -----------------------------
        # 6ï¸âƒ£ ìµœì¢… ê²°ê³¼ ë°˜í™˜
        # -----------------------------
        parsed["disposal_methods"] = disposal_methods
        parsed["tips"] = tips

        print("[DEBUG] parsed =", parsed)
        return JSONResponse({"result": parsed}, status_code=200)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
